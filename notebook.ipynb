{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "laughing-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing, decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-sunrise",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "graphic-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "surprised-spouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.target == 1].text.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "lasting-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.target == 0].text.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "early-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_all_text(x):\n",
    "    if not (pd.isna(x.keyword) or pd.isna(x.location)):\n",
    "        return str(x.keyword) + ' ' + str(x.location) + ' ' + str(x.text)  \n",
    "    else:\n",
    "        return x.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "cathedral-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df.apply(lambda x: mix_all_text(x) ,axis=1)\n",
    "test_df['text'] = test_df.apply(lambda x: mix_all_text(x) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "equivalent-leisure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>heatwave liverpool heatwave greatbritishbakeof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>bioterrorism creation of ai climate change bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>floods who is bringing the tornadoes and flood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>collided tennessee collided on page of of afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>hostages render assistance gain as proxy for y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>drought at work drought mane im not a raiders ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>demolition us pr demolition treyarch davidvond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>bombed photo bombed http tco artumhmbhh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>suicidebombing australia suicidebombing erdoga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>burned upper st clair pa burned thomasvissman ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "4277  heatwave liverpool heatwave greatbritishbakeof...\n",
       "618   bioterrorism creation of ai climate change bio...\n",
       "4019  floods who is bringing the tornadoes and flood...\n",
       "1715  collided tennessee collided on page of of afte...\n",
       "4464  hostages render assistance gain as proxy for y...\n",
       "2886  drought at work drought mane im not a raiders ...\n",
       "2358  demolition us pr demolition treyarch davidvond...\n",
       "1105            bombed photo bombed http tco artumhmbhh\n",
       "6450  suicidebombing australia suicidebombing erdoga...\n",
       "1290  burned upper st clair pa burned thomasvissman ..."
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['text']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-strength",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "incredible-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def cleaning_function(a):\n",
    "    \"\"\"\n",
    "    function used for clining a list of strings\n",
    "    \"\"\"\n",
    "    a1 = lower_array(a)\n",
    "    a2 = remove_punct_array(a1)\n",
    "    return a2\n",
    "\n",
    "def lower_array(a):\n",
    "    return [(str(word)).lower() for word in a]\n",
    "\n",
    "def remove_punct(s):\n",
    "    # replace - and / by space\n",
    "    s0 = s.replace('-', ' ').replace('/', ' ')\n",
    "    # replace 2+ spaces by 1 space\n",
    "    t = re.compile(r\"\\s+\")\n",
    "    s1 = t.sub(\" \", s0).strip()\n",
    "    # remove punctuations\n",
    "    s2 = re.sub(r'[^A-Za-z ]+', '', s1)\n",
    "    # remove first space   \n",
    "    s3 = re.sub('^\\s', '', s2)\n",
    "    # remove last space   \n",
    "    s4 = s3.rstrip()\n",
    "    return s4\n",
    "\n",
    "def remove_punct_array(a):\n",
    "    return [remove_punct(str(word)) for word in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "hired-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.text = cleaning_function(train_df.text)\n",
    "test_df.text = cleaning_function(test_df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-outreach",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-advance",
   "metadata": {},
   "source": [
    "### Using a simple count vextorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "forced-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "## let's get counts for the first 5 tweets in the data\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "acquired-deficit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 52)\n",
      "[[0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "matched-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-cooking",
   "metadata": {},
   "source": [
    "### Using Tf-idf (Term frequency - Inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "arabic-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.TfidfVectorizer()\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "perfect-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 52)\n",
      "[[0.         0.23336118 0.28924517 0.23336118 0.         0.\n",
      "  0.         0.         0.         0.         0.28924517 0.28924517\n",
      "  0.         0.         0.         0.         0.28924517 0.\n",
      "  0.         0.         0.         0.         0.         0.28924517\n",
      "  0.         0.         0.         0.28924517 0.         0.\n",
      "  0.         0.         0.28924517 0.         0.         0.\n",
      "  0.         0.28924517 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.28924517\n",
      "  0.23336118 0.         0.28924517 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "religious-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-stone",
   "metadata": {},
   "source": [
    "## LSA (Latent Semantic Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "designing-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = decomposition.TruncatedSVD(n_components=30, n_iter=20, random_state=42)\n",
    "train_matrix = svd.fit_transform(train_vectors)\n",
    "test_matrix = svd.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-failure",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "going-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our vectors are really big, so we want to push our model's weights\n",
    "## toward 0 without completely discounting different words - ridge regression \n",
    "## is a good way to do this.\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "numerical-station",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6122449 , 0.54136986, 0.66298343])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_matrix, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "color-official",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_matrix, train_df[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-citizenship",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "usual-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sample_submission[\"target\"] = clf.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "compatible-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "approved-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-singapore",
   "metadata": {},
   "source": [
    "## Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "looking-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.DataFrame({'text':test_df['text'] , 'is_disaster': sample_submission[\"target\"].astype(bool)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "serious-producer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>rescue usa rescue beauty deals http tco eudept...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>airplaneaccident california usa airplaneaccide...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>buildingsonfire las vegas buildingsonfire ther...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>pandemonium nigeria pandemonium pandemonium in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>loudbang kenya loudbang ibliz breaking news un...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  is_disaster\n",
       "2418  rescue usa rescue beauty deals http tco eudept...         True\n",
       "61    airplaneaccident california usa airplaneaccide...         True\n",
       "547   buildingsonfire las vegas buildingsonfire ther...         True\n",
       "2279  pandemonium nigeria pandemonium pandemonium in...         True\n",
       "2022  loudbang kenya loudbang ibliz breaking news un...         True"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check[df_check.is_disaster == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "selected-malta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>evacuation my school is so fucking dumb they j...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>violentstorm hippiexox if the word violent com...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>hazard road hazard e confederate ave se morela...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>volcano baker louisiana volcano whats the hott...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>collide lehigh acres fl collide collide gatewa...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  is_disaster\n",
       "1451  evacuation my school is so fucking dumb they j...        False\n",
       "3067  violentstorm hippiexox if the word violent com...        False\n",
       "1771  hazard road hazard e confederate ave se morela...        False\n",
       "3095  volcano baker louisiana volcano whats the hott...        False\n",
       "744   collide lehigh acres fl collide collide gatewa...        False"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check[df_check.is_disaster == False].sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
